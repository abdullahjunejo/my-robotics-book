"use strict";(globalThis.webpackChunkmy_robotics_book=globalThis.webpackChunkmy_robotics_book||[]).push([[8181],{4442(e,n,t){t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"robot-perception","title":"\ud83d\udc41\ufe0f 6. Sensor Fusion & Perception","description":"Robot apne mahool ko sensors ke zariye dekhta aur samajhta hai.","source":"@site/docs/06-perception.md","sourceDirName":".","slug":"/robot-perception","permalink":"/my-robotics-book/docs/robot-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/abdullahjunejo/my-robotics-book/edit/main/docs/06-perception.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"id":"robot-perception","slug":"/robot-perception","title":"\ud83d\udc41\ufe0f 6. Sensor Fusion & Perception"},"sidebar":"tutorialSidebar","previous":{"title":"\ud83e\uddbe 5. Humanoid Locomotion","permalink":"/my-robotics-book/docs/locomotion-control"},"next":{"title":"\u2699\ufe0f 7. Actuators & Torque Control","permalink":"/my-robotics-book/docs/robotic-actuation"}}');var i=t(4848),s=t(8453),r=t(9103);const a={sidebar_position:6,id:"robot-perception",slug:"/robot-perception",title:"\ud83d\udc41\ufe0f 6. Sensor Fusion & Perception"},l="Robotic Perception",c={},d=[{value:"6.1 The Multimodal Sensor Suite",id:"61-the-multimodal-sensor-suite",level:2},{value:"6.2 Semantic Segmentation &amp; Scene Parsing",id:"62-semantic-segmentation--scene-parsing",level:2},{value:"6.3 Technical Implementation: Obstacle Detection",id:"63-technical-implementation-obstacle-detection",level:2}];function h(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.A,{chapterTitle:"Introduction to Neural Dynamics"}),"\n",(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"robotic-perception",children:"Robotic Perception"})}),"\n",(0,i.jsx)(n.p,{children:"Robot apne mahool ko sensors ke zariye dekhta aur samajhta hai."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LiDAR:"})," 3D mapping ke liye laser ka istemal karna."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Computer Vision:"})," Cameras ke zariye raste mein aane wali cheezon ko pehchanna."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Depth Sensing:"})," Cheezon ka robot se fasla (distance) maloom karna."]}),"\n"]}),"\n",(0,i.jsx)(n.h1,{id:"understanding-the-3d-world",children:"Understanding the 3D World"}),"\n",(0,i.jsx)(n.p,{children:'Physical AI relies on high-fidelity perception to interact with dynamic environments safely. This chapter explores how robots "see" and "feel" their surroundings.'}),"\n",(0,i.jsx)(n.h2,{id:"61-the-multimodal-sensor-suite",children:"6.1 The Multimodal Sensor Suite"}),"\n",(0,i.jsxs)(n.p,{children:["To achieve robust autonomy, robots use ",(0,i.jsx)(n.strong,{children:"Sensor Fusion"}),", combining data from multiple sources:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Active Sensing (LiDAR):"}),' Light Detection and Ranging. These sensors emit millions of laser pulses per second to create a 3D "Point Cloud" of the room.']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Passive Sensing (RGB-D):"})," Depth cameras like Intel RealSense provide color images and distance data for every pixel."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tactile Feedback:"}),' Pressure sensors in the robot\'s hands that allow it to "feel" if an object is slipping.']}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"62-semantic-segmentation--scene-parsing",children:"6.2 Semantic Segmentation & Scene Parsing"}),"\n",(0,i.jsxs)(n.p,{children:["Unlike simple object detection, ",(0,i.jsx)(n.strong,{children:"Semantic Segmentation"})," allows the robot to classify every single pixel."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Static Obstacles:"})," Walls, floors, and heavy furniture."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dynamic Obstacles:"})," Humans, pets, and other moving robots."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Traversable Surfaces:"})," Areas where the robot's legs or wheels can safely move."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"63-technical-implementation-obstacle-detection",children:"6.3 Technical Implementation: Obstacle Detection"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\ndef analyze_depth_buffer(depth_map, safety_margin=0.45):\n    """\n    Analyzes depth data to trigger an emergency stop if \n    an object is within the safety threshold.\n    """\n    closest_point = np.min(depth_map)\n    if closest_point < safety_margin:\n        return f"CRITICAL_STOP: Object detected at {closest_point:.2f}m"\n    return "PATH_CLEAN: Normal Operation"\n\n# Simulated 10x10 depth frame\nsimulated_view = np.random.uniform(0.3, 5.0, (10, 10))\nprint(analyze_depth_buffer(simulated_view))\n'})})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453(e,n,t){t.d(n,{R:()=>r,x:()=>a});var o=t(6540);const i={},s=o.createContext(i);function r(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(s.Provider,{value:n},e.children)}},9103(e,n,t){t.d(n,{A:()=>r});var o=t(6540);const i={actionContainer:"actionContainer_Oos2",levelSelector:"levelSelector_Hxg7",selectBox:"selectBox_dsp1",personalizeBtn:"personalizeBtn_siSC",urduBtn:"urduBtn_NV2_",sidebarLabelFix:"sidebarLabelFix_NGs4"};t(8193);var s=t(4848);function r({chapterTitle:e}){const[n,t]=(0,o.useState)("beginner");(0,o.useEffect)(()=>{if("undefined"!=typeof window){const e=localStorage.getItem("userSoftware");e&&t(e)}},[]);const r=t=>{let o="";if(o="urdu"===t?`Please provide a detailed summary of the chapter "${e}" in Urdu language.`:`I am currently at the ${n} level. Please personalize and explain the main concepts of the chapter "${e}" in a way that matches my expertise.`,"undefined"!=typeof window){const e=new CustomEvent("openChat",{detail:o});window.dispatchEvent(e)}};return(0,s.jsxs)("div",{className:i.actionContainer,children:[(0,s.jsxs)("div",{className:i.levelSelector,children:[(0,s.jsx)("label",{className:i.label,children:"My Level: "}),(0,s.jsxs)("select",{value:n,onChange:e=>{const n=e.target.value;t(n),"undefined"!=typeof window&&localStorage.setItem("userSoftware",n)},className:i.selectBox,children:[(0,s.jsx)("option",{value:"beginner",children:"Beginner"}),(0,s.jsx)("option",{value:"intermediate",children:"Intermediate"}),(0,s.jsx)("option",{value:"expert",children:"Expert"})]})]}),(0,s.jsx)("button",{onClick:()=>r("personalize"),className:i.personalizeBtn,children:"\u2728 Personalize Content"}),(0,s.jsx)("button",{onClick:()=>r("urdu"),className:i.urduBtn,children:"\ud83c\udfaf Urdu Summary"})]})}}}]);